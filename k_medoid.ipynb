{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8795ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from myf import calculate_g_x\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from tslearn.metrics import dtw\n",
    "from tslearn.clustering import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e6d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.clustering.k_medoids import TimeSeriesKMedoids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645aef2",
   "metadata": {},
   "source": [
    "we alread save npy, you can skip the following part (to the cell with np.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a58c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(\"smoothed_multi_train_157\")\n",
    "train_list = []\n",
    "for train_file in train_files:\n",
    "    file_path = os.path.join(\"smoothed_multi_train_157\", train_file)\n",
    "    train_list.append(np.load(file_path))\n",
    "train_data = np.array(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1dd75fa-cb2e-4714-b6ad-7c1a4bfaef91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[169.99629109, 173.17667587, 166.55681452, ..., 122.13828283,\n",
       "        117.16131907, 109.759095  ],\n",
       "       [100.30668828,  91.34007695,  87.84422476, ..., 108.52914288,\n",
       "        105.57954702, 104.81906166],\n",
       "       [135.38118147, 133.47623665, 129.13926266, ..., 151.5292107 ,\n",
       "        155.72520914, 159.64878225],\n",
       "       ...,\n",
       "       [210.55637369, 213.97072095, 217.4587077 , ..., 225.76257176,\n",
       "        215.98735536, 207.38961299],\n",
       "       [221.22399297, 227.87975489, 233.78071415, ..., 199.31450247,\n",
       "        192.75621684, 186.42376328],\n",
       "       [ 80.72335148,  73.72034821,  68.17425233, ..., 106.53745433,\n",
       "        100.66003137,  87.51722628]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to preprocessing data first\n",
    "log_train = Parallel(n_jobs=-1)(\n",
    "    delayed(calculate_g_x)(train_data[i]) for i in range(len(train_data))\n",
    ")\n",
    "log_train = np.array(log_train)\n",
    "np.save(\"log_smoothed_multi_train_157.npy\", log_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088d87a",
   "metadata": {},
   "source": [
    "you can start from the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4b67f1-e0c7-4042-866c-6cd9cff88efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train = np.load(\"log_smoothed_multi_train_157.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e85e1",
   "metadata": {},
   "source": [
    "because it is time consuming to calculate every pair of dtw distances. we leverage the central limit thereom here to estimate the 20th  quantile of all the pairwise distances with sample len 157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58fecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_limit_quantile_20(\n",
    "    profiles,\n",
    "    n_jobs=-1,\n",
    "):\n",
    "    n = len(profiles)\n",
    "\n",
    "    indices = list(combinations(range(n), 2))\n",
    "\n",
    "    def compute_dtw(x1, x2):\n",
    "        return dtw(x1, x2)\n",
    "\n",
    "    # Calculate the score between 2 signals\n",
    "\n",
    "    distances = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_dtw)(profiles[i], profiles[j]) for i, j in indices\n",
    "    )\n",
    "\n",
    "    distances = np.array(distances)\n",
    "\n",
    "    return np.nanquantile(distances, 0.2)\n",
    "\n",
    "    # get 20th quantile of the distnaces samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6dc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i in range(100):\n",
    "    sample_indices = np.random.choice(len(log_train), size=100, replace=True)\n",
    "    sampled_cases = log_train[sample_indices]\n",
    "    samples.append(sampled_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0823e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_results = Parallel(n_jobs=-1)(\n",
    "    delayed(central_limit_quantile_20)(sample_set) for sample_set in samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a7a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = np.mean(np.array(quantile_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9aefb6",
   "metadata": {},
   "source": [
    "use only use tau = 0.3*gamma here for testing, because it would run for a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e436ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_ratios = [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03dda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = []\n",
    "for tau_ratio in tau_ratios:\n",
    "    tau = gamma * tau_ratio\n",
    "    threshold = gamma / 2 + gamma + tau  # radius upper bound\n",
    "    threshold_list.append(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a25ad4",
   "metadata": {},
   "source": [
    "start training k medoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59734bd2-a316-45c9-923b-d82ad74775d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train = np.expand_dims(log_train, axis=1)  # (n,1,m) to implement fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46dd02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2d shape (n_cases, n_timepoints)\n",
    "# Example of PAM clustering\n",
    "# for cluster_num, choose according to motifs num\n",
    "ks = [53]\n",
    "for i, k in enumerate(ks):\n",
    "    km = TimeSeriesKMedoids(n_clusters=k, random_state=1)\n",
    "    km.fit(log_train)\n",
    "    print(\"end\")\n",
    "    # Save k_medoids to a file\n",
    "    with open(f\"k_medoids_multi_{threshold_list[i]}_157.pkl\", \"wb\") as f:\n",
    "        pickle.dump(km, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7664a-38ea-4573-ba83-8f649c2d6a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation use tukey test to remove outlier or 5-10% or smaller than certain numbers of cases\n",
    "#validation_files = os.listdir(\"smoothed_multi_val_157\")\n",
    "#validation_list = []\n",
    "#for validation_file in validation_files:\n",
    "#    file_path = os.path.join(\"smoothed_multi_val_157\", validation_file)\n",
    "#    validation_list.append(np.load(file_path))\n",
    "#validation_data = np.array(validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1bf2e-8c33-459c-9610-e2343000a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to preprocessing data first\n",
    "#log_val = Parallel(n_jobs=-1)(\n",
    "#    delayed(calculate_g_x)(validation_data[i]) for i in range(len(validation_data))\n",
    "#)\n",
    "#log_val = np.array(log_val)\n",
    "#np.save(\"log_smoothed_multi_val_157.npy\", log_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db467da",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_val = np.load(\"log_smoothed_multi_val_157.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005db330",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train = np.squeeze(log_train)  # (n,1,m) to (n,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798705a0",
   "metadata": {},
   "source": [
    "the following evaluation part we use only one k medoid for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57484c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_medoid_path = \"k_medoids_multi_5.203641425222681_157.pkl\"\n",
    "threshold = float(k_medoid_path.split(\"_\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "043374c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = pickle.load(open(k_medoid_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07329167-ab67-44b0-9296-7b758619beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = km.predict(log_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f454e727-1c42-4037-84a8-26c5a83ec895",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0b890f-69fd-42e6-90f1-5c97866fd34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_threshold(threshold, log_val_e, val_result, centers):\n",
    "    center = np.squeeze(centers[val_result])  # (1,1440) to (1440,)\n",
    "    if dtw(log_val_e, center) >= threshold:\n",
    "        return -1\n",
    "    return val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bef5db5-b0aa-476c-8964-d4b0aefeb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_no_outlier = Parallel(n_jobs=-1)(\n",
    "    delayed(testing_threshold)(threshold, log_val[i], val_results[i], centers)\n",
    "    for i in range(len(log_val))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6676fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results_no_outlier = np.array(val_results_no_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7885dd0-ce0a-4af7-ad5e-f58ce8f894b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results_no_outlier[val_results_no_outlier == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe342b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4222, 157, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.expand_dims(log_val, axis=-1)  # n_ts, sz, d\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16e96787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05390101263706613"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(X, val_results, metric=\"dtw\", n_jobs=-1)  # labels: shape = [n_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d32da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
